{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42529738",
   "metadata": {},
   "source": [
    "# Chapter 2 (Handling Files, Cameras, and GUIs)\n",
    "\n",
    "In this chapter the Author concentrated on the following:\n",
    "- Basic I/O Operations\n",
    "- Reading/writing an image file\n",
    "- Displaying images in a window\n",
    "- Why is the Python module called cv2 not cv?\n",
    "- Modes of imread()\n",
    "- Modes of imwrite()\n",
    "- Converting between an image and raw bytes\n",
    "- Accessing image data with numpy.array\n",
    "- Reading/writing a video file\n",
    "- Capturing camera frames\n",
    "- Displaying camera frames in a window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09010c47",
   "metadata": {},
   "source": [
    "## Basic I/O Operations\n",
    "\n",
    "There are some operations can be done on the image:\n",
    "- Getting images or videos as input from disk , camera, online. \n",
    "- Producing images or videos as output into the disk or rows of data.\n",
    "\n",
    "## Reading/Writing an image file\n",
    "\n",
    "OpenCV provides the imread() and imwrite() functions that support various file formats for still images. Each pixel has a value, but the difference is in how the pixel is represented. In case Gray scale images, each pixel is represented by a single 8-bit integer, which means that the values for each pixel are in the 0-255 range.\n",
    "\n",
    "\n",
    "imread() by default read an image in BGR (Blue, Green, Red), but tou can change it as in our example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43a4e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eca6417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45, 46, 48, ..., 13, 13, 13],\n",
       "       [44, 46, 48, ..., 13, 13, 13],\n",
       "       [44, 45, 47, ..., 13, 13, 13],\n",
       "       ...,\n",
       "       [30, 30, 30, ..., 25, 25, 25],\n",
       "       [31, 31, 31, ..., 26, 26, 26],\n",
       "       [32, 32, 32, ..., 27, 27, 27]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv.imread('photos/rose.jfif', cv.IMREAD_GRAYSCALE)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793a017e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 275)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtaining Image dimension (image structure)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea10f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 46, 48, 50, 53, 56, 58, 59, 58, 57, 56, 55, 54, 52, 51, 51, 45,\n",
       "       45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46,\n",
       "       46, 46, 46, 46, 46, 46, 52, 58, 67, 75, 80, 80, 77, 74, 77, 75, 70,\n",
       "       64, 58, 52, 48, 45, 32, 32, 32, 31, 31, 30, 30, 30, 33, 33, 34, 35,\n",
       "       37, 38, 39, 40, 44, 44, 44, 44, 44, 44, 44, 44, 43, 42, 41, 41, 40,\n",
       "       39, 38, 38, 36, 37, 37, 38, 39, 40, 41, 41, 45, 46, 47, 48, 49, 51,\n",
       "       52, 52, 58, 57, 57, 57, 56, 56, 55, 55, 53, 52, 51, 50, 48, 47, 46,\n",
       "       45, 40, 40, 41, 42, 43, 44, 44, 45, 45, 44, 44, 44, 43, 43, 42, 42,\n",
       "       44, 43, 43, 43, 42, 42, 41, 41, 44, 44, 43, 43, 42, 42, 42, 41, 44,\n",
       "       43, 42, 40, 38, 36, 35, 34, 35, 34, 33, 32, 30, 29, 28, 27, 29, 29,\n",
       "       29, 28, 28, 27, 27, 27, 33, 33, 34, 36, 37, 39, 40, 40, 40, 40, 41,\n",
       "       41, 42, 42, 42, 43, 40, 40, 40, 39, 39, 38, 38, 38, 40, 40, 40, 40,\n",
       "       40, 40, 40, 40, 36, 36, 35, 33, 32, 31, 30, 29, 29, 29, 28, 28, 27,\n",
       "       27, 27, 27, 26, 26, 26, 26, 26, 26, 26, 26, 30, 30, 30, 29, 29, 29,\n",
       "       28, 28, 28, 27, 26, 25, 24, 22, 21, 21, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19, 19, 19, 18, 17, 17, 16, 15, 14, 13, 13,\n",
       "       13, 13, 13], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtaining 1st row in the Image\n",
    "image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e70dd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtaining the 1st pixel value at position(0,0)\n",
    "image[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "032340ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imshow('gray', image)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae9bd90",
   "metadata": {},
   "source": [
    "Lets see an interesting example using OpenCV, where the image is in greyscale mode but it's read as BGR. How's the pixel's value represented?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64698342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((275, 3), (183, 275, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgr_image = cv.imread('photos/rose.jfif')\n",
    "bgr_image[0].shape, bgr_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd14d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 45, 45], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgr_image[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7841fc",
   "metadata": {},
   "source": [
    "We notice from above, that the although the image is gray, it is read as BGR, it has three channel. Also, we notice that the value has been repeated in the 2nd and 3rd channel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b39e548",
   "metadata": {},
   "source": [
    "## Displaying images in a window\n",
    "cv.imshow() can be used to display the image in python. But if you usse it only, the image will be displayed, and will disappear immediately. So, we need cv.waitKey(). \n",
    "\n",
    "cv.waitKey() takes value, this value can be:\n",
    "- it waits miliseconds in case of positive vale.\n",
    "\n",
    "- it ts for a key event infinitely (when delayâ‰¤0 ) \n",
    "\n",
    "Note, cv.waitKey() returns the code of the pressed key or -1 if no key was pressed before the specified time had elapsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8af2fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "imshow() takes two parameters: the name of the frame and the image itself.\n",
    "\n",
    "'''\n",
    "\n",
    "cv.imshow('bgr', bgr_image)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce90655",
   "metadata": {},
   "source": [
    "## Why is the Python module called cv2 not cv?\n",
    "\n",
    "Because it has introduced a better API, which leverages object-oriented programming as opposed to the previous cv module, which adhered to a more procedural style of programming.\n",
    "\n",
    "## Modes of imread()\n",
    "\n",
    "- IMREAD_ANYCOLOR = 4\n",
    "- IMREAD_ANYDEPTH = 2\n",
    "- IMREAD_COLOR = 1\n",
    "- IMREAD_GRAYSCALE = 0\n",
    "- IMREAD_LOAD_GDAL = 8\n",
    "- IMREAD_UNCHANGED = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31344007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colored_image = cv.imread('photos/coloredRose.jfif')\n",
    "cv.imshow('bgr', colored_image)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c84b95f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20, 45, 19],\n",
       "       [27, 55, 25],\n",
       "       [35, 71, 35],\n",
       "       [40, 84, 43],\n",
       "       [45, 91, 49],\n",
       "       [47, 93, 51],\n",
       "       [48, 92, 53],\n",
       "       [48, 91, 54],\n",
       "       [49, 93, 57],\n",
       "       [46, 90, 54]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colored_image[0][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c4626",
   "metadata": {},
   "source": [
    "## Modes of imwrite()\n",
    "\n",
    "The imwrite() function requires an image to be in the BGR or grayscale format with a certain number of bits per channel that the output format can support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c77ba322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imwrite('photos/MyPicGray.png', colored_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fa091a",
   "metadata": {},
   "source": [
    "## Converting between an image and raw bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970f745f",
   "metadata": {},
   "source": [
    " An 8-bit grayscale image is a 2D array containing byte values. A 24-bit BGR image is a 3D array, which also contains byte values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65ee9e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 238, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colored_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5f656a",
   "metadata": {},
   "source": [
    "In colored_image:\n",
    "\n",
    "- The first index is the pixel's y coordinate or row, 0 being the top. \n",
    "- The second index is the pixel's x coordinate or column, 0 being the leftmost. \n",
    "- The third index (if applicable) represents a color channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da740d38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[20, 27, 35, ..., 22, 16, 13],\n",
       "        [22, 27, 37, ..., 14, 13, 12],\n",
       "        [25, 30, 38, ...,  9, 12,  9],\n",
       "        ...,\n",
       "        [ 9, 11, 11, ..., 42, 38, 36],\n",
       "        [10, 12, 10, ..., 42, 38, 35],\n",
       "        [10, 12, 10, ..., 42, 37, 34]], dtype=uint8),\n",
       " array([[45, 55, 71, ..., 46, 40, 36],\n",
       "        [47, 58, 73, ..., 35, 32, 32],\n",
       "        [50, 61, 76, ..., 22, 25, 26],\n",
       "        ...,\n",
       "        [11, 10, 10, ..., 78, 74, 73],\n",
       "        [12, 11,  9, ..., 78, 74, 72],\n",
       "        [12, 11,  9, ..., 78, 73, 71]], dtype=uint8),\n",
       " array([[19, 25, 35, ..., 22, 16, 14],\n",
       "        [21, 27, 37, ..., 13, 13, 13],\n",
       "        [24, 30, 40, ...,  6, 11, 13],\n",
       "        ...,\n",
       "        [12, 12, 12, ..., 32, 28, 27],\n",
       "        [13, 13, 11, ..., 32, 28, 26],\n",
       "        [13, 13, 11, ..., 32, 27, 25]], dtype=uint8))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To obtain each channel individually\n",
    "r1 = colored_image[:,:,0] # get blue channel the 1st channel of 3 channels is 0\n",
    "g1 = colored_image[:,:,1] # get green channel the 2nd channel of the 3 channels is 1\n",
    "b1 = colored_image[:,:,2] # get red channel the 3rd channels of the channels is 2\n",
    "r1,g1,b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b7f2647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((148, 238), (148, 238), (148, 238))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.shape,g1.shape,b1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79875691",
   "metadata": {},
   "source": [
    "Provided that an image has 8 bits per channel, we can cast it to a standard Python bytearray, which is one-dimensional as follows,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b4601ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "byteArray = bytearray(colored_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587c4de4",
   "metadata": {},
   "source": [
    "Conversely, provided that bytearray contains bytes in an appropriate order, we can cast and then reshape it to get a numpy.array type that is an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "608dd148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20, 45, 19],\n",
       "       [27, 55, 25],\n",
       "       [35, 71, 35],\n",
       "       [40, 84, 43],\n",
       "       [45, 91, 49],\n",
       "       [47, 93, 51],\n",
       "       [48, 92, 53],\n",
       "       [48, 91, 54],\n",
       "       [49, 93, 57],\n",
       "       [46, 90, 54]], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width=238\n",
    "height= 148\n",
    "bgrImage = np.array(byteArray).reshape(height, width, 3)\n",
    "bgrImage[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a51145d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imshow('BGRByteArray', bgrImage)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccff366",
   "metadata": {},
   "source": [
    "## Accessing image data with numpy.array\n",
    "Let's explore image manipulations from the start and step by step though, with a basic example: Let's say that you want to change the blue value of a particular pixel, for example, the pixel at coordinates, (150, 120)\n",
    "\n",
    "The numpy.array type provides a very handy method, item(), which takes three parameters: the x (or left) position, y (or top), and the index within the array at (x, y) position and returns the value at the index position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88439fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colored_image.item(140, 120, 0) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdc5e51",
   "metadata": {},
   "source": [
    " Another itemset() method sets the value of a particular channel of a particular pixel to a specified value (itemset()\n",
    "takes two arguments: a three-element tuple (x, y, and index) and the new value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86b3fbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colored_image.itemset( (0, 0, 0), 0)\n",
    "cv.imshow('Itemset', colored_image)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90268446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 45, 19], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the value at the 0,0,0\n",
    "colored_image[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82620b72",
   "metadata": {},
   "source": [
    "One of interesting things we can do by accessing raw pixels with NumPy's array indexing is defining regions of interests (ROI). Once the region is defined, we can perform a number of operations, namely, binding this region to a variable, and then even defining a second region and assigning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6644b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_roi = colored_image[0:40, 0:40]\n",
    "colored_image[100:140, 100:140] = my_roi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3e14c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imshow('Itemset', colored_image)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40abe267",
   "metadata": {},
   "source": [
    "Finally, there are a few interesting details we can obtain from numpy.array, such as \n",
    "\n",
    "- Shape: NumPy returns a tuple containing the width, height, andâ€”if the image is in colorâ€”the number of channels. \n",
    "  This is useful to debug a type of image; if the image is monochromatic or grayscale, it will not contain a channel's value.\n",
    "\n",
    "\n",
    "- Size: This property refers to the size of an image in pixels.\n",
    "\n",
    "\n",
    "- Datatype: This property refers to the datatype used for an image (normally a variation of an unsigned integer type and the bits supported by this type, that is, uint8)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee981de9",
   "metadata": {},
   "source": [
    "## Reading/writing a video file\n",
    "\n",
    "OpenCV provides the VideoCapture and VideoWriter classes that support various video file formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96cc6a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# videoCapture is an object which can be used to get input video features via get() function\n",
    "videoCapture = cv.VideoCapture('Video.mp4')\n",
    "#Obtaining frame per second from the input video\n",
    "fps = videoCapture.get(cv.CAP_PROP_FPS)\n",
    "\n",
    "#obtainning the video size from hight and width of input video\n",
    "size = (int(videoCapture.get(cv.CAP_PROP_FRAME_WIDTH)), \n",
    "        int(videoCapture.get(cv.CAP_PROP_FRAME_HEIGHT)))\n",
    "'''\n",
    "VideoWriter needs video's filename and video codec, frame per second, size\n",
    "\n",
    "These are the codec's  options that are included:\n",
    "\n",
    "â€¢ cv2.VideoWriter_fourcc('I','4','2','0'): This option is an uncompressed YUV encoding, 4:2:0 chroma subsampled. \n",
    "This encoding is widely compatible but produces large files. The file extension should be .avi.\n",
    "\n",
    "â€¢ cv2.VideoWriter_fourcc('P','I','M','1'): This option is MPEG-1. The file extension should be .avi.\n",
    "\n",
    "â€¢ cv2.VideoWriter_fourcc('X','V','I','D'): This option is MPEG-4 and a preferred option if you want the resulting \n",
    "video size to be average. The file extension should be .avi.\n",
    "\n",
    "â€¢ cv2.VideoWriter_fourcc('T','H','E','O'): This option is Ogg Vorbis.The file extension should be .ogv.\n",
    "\n",
    "â€¢ cv2.VideoWriter_fourcc('F','L','V','1'): This option is a Flash video. The file extension should be .flv\n",
    "\n",
    "'''\n",
    "videoWriter = cv.VideoWriter( 'MyOutputVid.avi', cv.VideoWriter_fourcc('X','V','I','D'), fps, size)\n",
    "\n",
    "#Read the captured video 1st frame\n",
    "success, frame = videoCapture.read()\n",
    "\n",
    "#For debugging\n",
    "print(success)\n",
    "# Loop until there are no more frames.\n",
    "while success: \n",
    "    #Write every frame until success=False\n",
    "    videoWriter.write(frame)\n",
    "    success, frame = videoCapture.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6676907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c321e443",
   "metadata": {},
   "source": [
    "## Capturing camera frames\n",
    "\n",
    "A stream of camera frames is represented by the VideoCapture class too. However,for a camera, we construct a VideoCapture class by passing the camera's device index instead of a video's filename.\n",
    "\n",
    "Note, \n",
    "\n",
    "- In the following piece of code has assumed the fps because the get() method of a VideoCapture class does not return an accurate value for the camera's frame rate; it always returns 0. So, we should have our own assumption about the fps value. It may come from an average of fps of any video.\n",
    "\n",
    "- If an invalid index is used to construct a VideoCapture class, the VideoCapture class will not yield any frames; its read() method will return (false, None).  A good way to prevent it from trying to retrieve frames from VideoCapture that were not opened correctly is to use the VideoCapture.isOpened() method, which returns a Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8358425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#0 is the index of your camera\n",
    "cameraCapture = cv.VideoCapture(0)\n",
    "\n",
    "fps = 30 # an assumption\n",
    "# defining the size of onput frame\n",
    "size = (int(cameraCapture.get(cv.CAP_PROP_FRAME_WIDTH)), int(cameraCapture.get(cv.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "videoWriter = cv.VideoWriter('MyCamVid.avi', cv.VideoWriter_fourcc('I','4','2','0'),fps, size)\n",
    "success, frame = cameraCapture.read()\n",
    "numFramesRemaining = 10 * fps - 1\n",
    "print(success)\n",
    "while success and numFramesRemaining > 0:\n",
    "    videoWriter.write(frame)\n",
    "    success, frame = cameraCapture.read()\n",
    "    numFramesRemaining -= 1\n",
    "    cameraCapture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f5aad2",
   "metadata": {},
   "source": [
    "The number of cameras and their order is of course system-dependent. Unfortunately, OpenCV does not provide any means of querying the number of cameras or their properties.\n",
    "\n",
    "The read() method is inappropriate incase synchronizing a set of cameras (such as a stereo camera or Kinect). Then, we use the grab() and retrieve() methods instead.\n",
    "\n",
    "cameraCapture1 = cv.VideoCapture(index_camer1)\n",
    "\n",
    "cameraCapture0 = cv.VideoCapture(index_camer0)\n",
    "\n",
    "\n",
    "success0 = cameraCapture0.grab()\n",
    "\n",
    "success1 = cameraCapture1.grab()\n",
    "\n",
    "if success0 and success1:\n",
    "\n",
    "    frame0 = cameraCapture0.retrieve()\n",
    "    \n",
    "    frame1 = cameraCapture1.retrieve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51309ec7",
   "metadata": {},
   "source": [
    "## Displaying camera frames in a window\n",
    "\n",
    " Let's look at an example where we show the frames of a live camera input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ffb5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing camera feed. Click window or press any key tostop.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2 as cv\n",
    "\n",
    "clicked=False\n",
    "\n",
    "def onMouse(event, x, y, flags, param):\n",
    "    #global keyword is used if you want to change a global variable inside a function.\n",
    "    global clicked\n",
    "    #Indicates that the left mouse button is double clicked\n",
    "    if event == cv.EVENT_LBUTTONDBLCLK:\n",
    "        clicked = True\n",
    "        \n",
    "        #print(clicked)\n",
    "        #print(x,y)\n",
    "        #print()\n",
    "\n",
    "\n",
    "# Obtain camera input\n",
    "cameraCapture = cv.VideoCapture(0)\n",
    "\n",
    "#method is used to create a window with a suitable name\n",
    "cv.namedWindow('MyWindow')\n",
    "\n",
    "#Sets mouse handler for the specified window. sets the onMouse() to handle the click event on MyWindow window. \n",
    "cv.setMouseCallback('MyWindow', onMouse)\n",
    "\n",
    "print('Showing camera feed. Click window or press any key tostop.')  \n",
    " \n",
    "#read the video frames    \n",
    "success, frame = cameraCapture.read()\n",
    "\n",
    "# while no click, or no button pressed, show the frame window\n",
    "while (success) and (not clicked) and (cv.waitKey(1) == -1):\n",
    "    cv.imshow('MyWindow', frame)\n",
    "    success, frame = cameraCapture.read()\n",
    "\n",
    "#For closing and releasing camera.    \n",
    "cv.destroyWindow('MyWindow')\n",
    "cameraCapture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2024582e",
   "metadata": {},
   "source": [
    "waitkey() can return a specific character, so If you want to define a special character for a list of ASCII keycodes, see \n",
    "http://www.asciitable.com/\n",
    "\n",
    "Note the following:\n",
    "- OpenCV windows are only updated when waitKey() is called, and waitKey() only captures input when an OpenCV window has focus.\n",
    "\n",
    "- The mouse callback events can be one of the following:\n",
    "\n",
    "  - cv2.EVENT_MOUSEMOVE: This event refers to mouse movement.\n",
    "   - cv2.EVENT_LBUTTONDOWN: This event refers to the left button down.\n",
    "  - cv2.EVENT_RBUTTONDOWN: This refers to the right button down\n",
    "  - cv2.EVENT_MBUTTONDOWN: This refers to the middle button down\n",
    "  - cv2.EVENT_LBUTTONUP: This refers to the left button up\n",
    "  - cv2.EVENT_RBUTTONUP: This event refers to the right button up\n",
    "  - cv2.EVENT_MBUTTONUP: This event refers to the middle button up\n",
    "  - cv2.EVENT_LBUTTONDBLCLK: This event refers to the left button being double-clicked\n",
    "  - cv2.EVENT_RBUTTONDBLCLK: This refers to the right button being double-clicked\n",
    "  - cv2.EVENT_MBUTTONDBLCLK: This refers to the middle button being double-clicked\n",
    "  - cv2.EVENT_FLAG_LBUTTON: This event refers to the left button being pressed\n",
    "  - cv2.EVENT_FLAG_RBUTTON: This event refers to the right button being pressed\n",
    "  - cv2.EVENT_FLAG_MBUTTON: This event refers to the middle button being pressed\n",
    "  - cv2.EVENT_FLAG_CTRLKEY: This event refers to the Ctrl key being pressed\n",
    "  - cv2.EVENT_FLAG_SHIFTKEY: This event refers to the Shift key being pressed\n",
    "  - cv2.EVENT_FLAG_ALTKEY: This event refers to the Alt key being pressed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ced27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79e8da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
